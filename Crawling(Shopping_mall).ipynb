{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shopping Mall Crawling\n",
    "* Made by Cheonsol Lee\n",
    "* Updated (20.08.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "- selenium\n",
    "- chrome drvier를 설치해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " def crawling(file_path, site_name, keyword, chromedriver_path):\n",
    "    # 현재날짜를 파일명에 기입 ex) (20200813)Auction_hemp.csv\n",
    "    year = datetime.today().year\n",
    "    month = datetime.today().month\n",
    "    day = datetime.today().day\n",
    "    \n",
    "    date = '(' + str(year) + str(month) + str(day) + ')'\n",
    "    \n",
    "    file_name = file_path + date + site_name + '_' + keyword + '.csv'\n",
    "    \n",
    "    # Auction은 정적크롤링(BeautifulSoup)\n",
    "    if(site_name == \"Auction\"):\n",
    "        print(\"쇼핑몰 : Auction!\")\n",
    "        res = requests.get('http://browse.auction.co.kr/search?keyword=' + keyword)\n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        items = soup.select(\"div.section--itemcard\")\n",
    "        \n",
    "        title_list = [item.select(\"div.area--itemcard_title span.text--title\")[0].get_text() for item in items]\n",
    "        price_list = [item.select(\"strong.text--price_seller\")[0].get_text() for item in items]\n",
    "        seller_list = [item.select(\"a.link--shop span\")[1].get_text() for item in items]\n",
    "        \n",
    "        df = pd.DataFrame({'title': title_list,'price': price_list, 'seller': seller_list})\n",
    "        df.index.name = 'index'\n",
    "    \n",
    "    # Danawa는 동적크롤링(selenium, BeautifulSoup)\n",
    "    if(site_name == \"Danawa\"):\n",
    "        print(\"쇼핑몰 : Danawa!\")\n",
    "        driver = webdriver.Chrome(chromedriver_path)\n",
    "        driver.get(\"http://search.danawa.com/dsearch.php?query=\" + keyword)\n",
    "        \n",
    "        # 명시적 대기 : 특정 태그가 로드될 때까지 대기\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'prod_name')))\n",
    "        \n",
    "        html = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        items = soup.select(\"div.main_prodlist li.prod_item\")\n",
    "\n",
    "        title_list = [item.select('p.prod_name a')[0].text for item in items]\n",
    "        price_list = [item.select('p.price_sect a strong')[0].text for item in items]\n",
    "        volume_list = [item.select('p.prod_name a')[0].text.split(\" \")[-1] for item in items]\n",
    "        \n",
    "        df = pd.DataFrame({'title': title_list,'price': price_list, 'volume': volume_list})\n",
    "        df.index.name = 'index'\n",
    "\n",
    "        \n",
    "    if(site_name == \"Amazone\"):\n",
    "        print(\"쇼핑몰 : Amazone!\")\n",
    "        driver = webdriver.Chrome(chromedriver_path)\n",
    "        driver.get(\"https://www.amazon.com/s?k=\" + keyword)\n",
    "\n",
    "        # 명시적 대기 : 특정 태그가 로드될 때까지 대기\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'nav-input')))\n",
    "\n",
    "        html = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        items = soup.select(\"div.sg-col-inner div.sg-col-inner\")\n",
    "        items = items[ : -1] # 마지막은 상품명이 아님.\n",
    "        \n",
    "        title_list = [item.select('h2 span')[0].text for item in items]\n",
    "        price_list = []\n",
    "        for item in items:\n",
    "            try:\n",
    "                item.select(\"span.a-price span.a-offscreen\")[0].get_text()\n",
    "                price = item.select(\"span.a-price span.a-offscreen\")[0].get_text()\n",
    "                price_list.append(price)\n",
    "            except:\n",
    "                price_list.append(0)\n",
    "        \n",
    "        df = pd.DataFrame({'title': title_list,'price': price_list})\n",
    "        df.index.name = 'index'\n",
    "        \n",
    "        \n",
    "    if(site_name == \"Bol\"):\n",
    "        print(\"쇼핑몰 : Bol!\")\n",
    "        res = requests.get('https://www.bol.com/nl/s/?searchtext=' + keyword)\n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        items = soup.select(\"li.product-item--row.js_item_root\")\n",
    "            \n",
    "        title_list = [item.select(\"div.product-title--inline a\")[0].get_text() for item in items]\n",
    "        price_list = []\n",
    "        for item in items:\n",
    "            tmp = re.split(\"\\n\", item.select(\"div.price-block__price\")[0].text.strip())\n",
    "            price_item = tmp[0] + ',' + tmp[1].strip()\n",
    "            price_list.append(price_item)\n",
    "                \n",
    "        df = pd.DataFrame({'title': title_list,'price': price_list})\n",
    "        df.index.name = 'index'\n",
    "    \n",
    "    \n",
    "    print(\"-----------------------아래는 테이블 구조입니다.-----------------------\")\n",
    "    print(df.head())\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    \n",
    "    df.to_csv(file_name, mode = 'w', encoding ='utf-8-sig', index = True, header = True)\n",
    "    print(\"저장되었습니다.파일을 확인해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User customizing\n",
    "- file_path : 저장위치 디렉토리\n",
    "- site_name : 'Aution' or 'Danawa'입력(2개만 가능)\n",
    "- keyword   : 'hemp', 'bean' 등 자유롭게 입력가능\n",
    "- chromedriver_path : 크롬드라이버가 설치된 절대경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일명 형태 : Auction_hemp.csv\n",
    "file_path = 'C:/Users/KSE/JupyterProjects/knowledge_structure/'\n",
    "site_name = 'Bol'\n",
    "keyword = 'hemp'\n",
    "\n",
    "# 크롬드라이버 절대경로\n",
    "chromedriver_path = 'C:/Users/KSE/Desktop/crawling/chromedriver.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쇼핑몰 : Bol!\n",
      "-----------------------아래는 테이블 구조입니다.-----------------------\n",
      "                                                   title  price\n",
      "index                                                          \n",
      "0            PuroCuro Hemp/CBD pleisters 64mg (32 stuks)  42,94\n",
      "1          PuroCuro Hemp/CBD pleisters - 16mg (32 stuks)  17,95\n",
      "2      Wiet Grinder Diamondgrind Luxe 4-delige Grinde...  19,95\n",
      "3                      MediHemp CBD Olie raw - 5% - 30ml  72,50\n",
      "4      Hennepvezelstrooisel bodembedekking knaagdier ...  12,62\n",
      "--------------------------------------------------------------------\n",
      "저장되었습니다.파일을 확인해주세요.\n"
     ]
    }
   ],
   "source": [
    "crawling(file_path, site_name, keyword, chromedriver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 8, 13, 21, 2, 26, 684087)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "year = datetime.today().year\n",
    "month = datetime.today().month\n",
    "day = datetime.today().day\n",
    "date = '(' + str(year) + str(month) + str(day) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '(' + str(year) + str(month) + str(day) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(2020813)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
