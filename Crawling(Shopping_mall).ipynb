{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shopping Mall Crawling\n",
    "* Made by Cheonsol Lee\n",
    "* Updated (20.08.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "- selenium\n",
    "- chrome drvier를 설치해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 정의부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(file_path, site_name, keyword, chromedriver_path):\n",
    "    file_name = file_path + site_name + '_' + keyword + '.csv'\n",
    "    \n",
    "    # 쇼핑몰 종류에 따라 다르게 크롤링\n",
    "    # Auction은 정적크롤링(BeautifulSoup)\n",
    "    if(site_name == \"Auction\"):\n",
    "        print(\"쇼핑몰 : Auction!\")\n",
    "        res = requests.get('http://browse.auction.co.kr/search?keyword=' + keyword)\n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        items = soup.select(\"div.section--itemcard\")\n",
    "        \n",
    "        title_list = [item.select(\"div.area--itemcard_title span.text--title\")[0].get_text() for item in items]\n",
    "        price_list = [item.select(\"strong.text--price_seller\")[0].get_text() for item in items]\n",
    "        seller_list = [item.select(\"a.link--shop span\")[1].get_text() for item in items]\n",
    "        \n",
    "        df = pd.DataFrame({'title': title_list,'price': price_list, 'seller': seller_list})\n",
    "        df.index.name = 'index'\n",
    "    \n",
    "    # Danawa는 동적크롤링(selenium, BeautifulSoup)\n",
    "    if(site_name == \"Danawa\"):\n",
    "        print(\"쇼핑몰 : Danawa!\")\n",
    "        driver = webdriver.Chrome(chromedriver_path)\n",
    "        driver.get(\"http://search.danawa.com/dsearch.php?query=\" + keyword)\n",
    "        \n",
    "        # 명시적 대기 : 특정 태그가 로드될 때까지 대기\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'prod_name')))\n",
    "        \n",
    "        html = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        items = soup.select(\"div.main_prodlist li.prod_item\")\n",
    "\n",
    "        title_list = [item.select('p.prod_name a')[0].text for item in items]\n",
    "        price_list = [item.select('p.price_sect a strong')[0].text for item in items]\n",
    "        volume_list = [item.select('p.prod_name a')[0].text.split(\" \")[-1] for item in items]\n",
    "        \n",
    "        df = pd.DataFrame({'title': title_list,'price': price_list, 'volume': volume_list})\n",
    "        df.index.name = 'index'\n",
    "\n",
    "        \n",
    "    if(site_name == \"Amazone\"):\n",
    "        print(\"쇼핑몰 : Amazone!\")\n",
    "        driver = webdriver.Chrome(chromedriver_path)\n",
    "        driver.get(\"https://www.amazon.com/s?k=\" + keyword)\n",
    "\n",
    "        # 명시적 대기 : 특정 태그가 로드될 때까지 대기\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'nav-input')))\n",
    "\n",
    "        html = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        items = soup.select(\"div.sg-col-inner div.sg-col-inner\")\n",
    "        items = items[ : -1] # 마지막은 상품명이 아님.\n",
    "        \n",
    "        title_list = [item.select('h2 span')[0].text for item in items]\n",
    "        price_list = []\n",
    "        for item in items:\n",
    "            try:\n",
    "                item.select(\"span.a-price span.a-offscreen\")[0].get_text()\n",
    "                price = item.select(\"span.a-price span.a-offscreen\")[0].get_text()\n",
    "                price_list.append(price)\n",
    "            except:\n",
    "                price_list.append(0)\n",
    "                \n",
    "        df = pd.DataFrame({'title': title_list,'price': price_list})\n",
    "        df.index.name = 'index'\n",
    "    \n",
    "    \n",
    "    print(\"-----------------------아래는 테이블 구조입니다.-----------------------\")\n",
    "    print(df.head())\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    \n",
    "    df.to_csv(file_name, mode = 'w', encoding ='utf-8-sig', index = True, header = True)\n",
    "    print(\"저장되었습니다.파일을 확인해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자정의 입력부\n",
    "- file_path : 저장위치 디렉토리\n",
    "- site_name : 'Aution' or 'Danawa'입력(2개만 가능)\n",
    "- keyword   : 'hemp', 'bean' 등 자유롭게 입력가능\n",
    "- chromedriver_path : 크롬드라이버가 설치된 절대경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일명 형태 : Auction_hemp.csv\n",
    "file_path = 'C:/Users/KSE/JupyterProjects/knowledge_structure/'\n",
    "site_name = 'Amazone'\n",
    "keyword = 'hemp'\n",
    "\n",
    "# 크롬드라이버 절대경로\n",
    "chromedriver_path = 'C:/Users/KSE/Desktop/crawling/chromedriver.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쇼핑몰 : Amazone!\n",
      "-----------------------아래는 테이블 구조입니다.-----------------------\n",
      "                                                   title   price\n",
      "index                                                           \n",
      "0      Hempz Sweet Pineapple & Honey Melon Moisturizi...  $19.51\n",
      "1      Manitoba Harvest Organic Hemp Hearts Shelled H...  $13.94\n",
      "2      Premium Hemp Gummies - Natural Hemp - Made in ...  $25.49\n",
      "3      Manitoba Harvest Hemp Hearts Shelled Hemp Seed...       0\n",
      "4      Hemp Cream - 2,000,000 - Relieve Muscle, Joint...  $22.95\n",
      "--------------------------------------------------------------------\n",
      "저장되었습니다.파일을 확인해주세요.\n"
     ]
    }
   ],
   "source": [
    "crawling(file_path, site_name, keyword, chromedriver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
